{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92eee1db-325f-4d29-8a37-0d9fb68c3c19",
   "metadata": {},
   "source": [
    "Sentiment Analysis for Amazon Reviews\n",
    "\n",
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd382ff-50ba-4ed8-895c-3f5c63e4678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d45fd5-829e-459d-bc96-500129e6524d",
   "metadata": {},
   "source": [
    "Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48e90d67-dce5-43a1-9a9d-b1222acebe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (1,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('1429_1.csv')\n",
    "\n",
    "# Taking only useful data from the dataset\n",
    "dataset = dataset.iloc[:,[17,16,14,11]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9940db2e-ee96-46d8-8573-401e027bd9bc",
   "metadata": {},
   "source": [
    "Taking Care of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34528636-7af5-4f7e-a6c9-8b2874f0df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discarding observations having missing data\n",
    "data = pd.DataFrame(dataset)\n",
    "dataset = data.dropna(axis = 0,how = 'any')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "# Storing rating separately to use it later\n",
    "rating = X[:, -1]\n",
    "\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Encoding True/False value at 1/0\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8710ccf9-d3a9-48c2-bf23-204bf302f9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kindle</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very fast</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beginner tablet for our 9 year old son.</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good!!!</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fantastic Tablet for kids</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34619</th>\n",
       "      <td>Wonderful unit</td>\n",
       "      <td>Can use it for best streaming. Can watch all t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34620</th>\n",
       "      <td>Works great</td>\n",
       "      <td>I am now able to stream tv and movies from aro...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34621</th>\n",
       "      <td>the best</td>\n",
       "      <td>best streaming device , very portable , amazin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34622</th>\n",
       "      <td>Love it</td>\n",
       "      <td>Simply the best to watch tv series and movies....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34623</th>\n",
       "      <td>Try it, you will like it</td>\n",
       "      <td>I was looking for ways to cut cost from a rais...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34061 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0  \\\n",
       "0                                       Kindle   \n",
       "1                                    very fast   \n",
       "2      Beginner tablet for our 9 year old son.   \n",
       "3                                      Good!!!   \n",
       "4                    Fantastic Tablet for kids   \n",
       "...                                        ...   \n",
       "34619                           Wonderful unit   \n",
       "34620                              Works great   \n",
       "34621                                 the best   \n",
       "34622                                  Love it   \n",
       "34623                 Try it, you will like it   \n",
       "\n",
       "                                                       1    2      3  \n",
       "0      This product so far has not disappointed. My c...  5.0   True  \n",
       "1      great for beginner or experienced person. Boug...  5.0   True  \n",
       "2      Inexpensive tablet for him to use and learn on...  5.0   True  \n",
       "3      I've had my Fire HD 8 two weeks now and I love...  4.0   True  \n",
       "4      I bought this for my grand daughter when she c...  5.0   True  \n",
       "...                                                  ...  ...    ...  \n",
       "34619  Can use it for best streaming. Can watch all t...  5.0   True  \n",
       "34620  I am now able to stream tv and movies from aro...  4.0   True  \n",
       "34621  best streaming device , very portable , amazin...  5.0  False  \n",
       "34622  Simply the best to watch tv series and movies....  5.0   True  \n",
       "34623  I was looking for ways to cut cost from a rais...  4.0   True  \n",
       "\n",
       "[34061 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c89c981b-4abf-4eb6-be68-ffff542bc661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Kindle'\n",
      "  'This product so far has not disappointed. My children love to use it and I like the ability to monitor control what content they see with ease.'\n",
      "  5.0]\n",
      " ['very fast'\n",
      "  'great for beginner or experienced person. Bought as a gift and she loves it'\n",
      "  5.0]\n",
      " ['Beginner tablet for our 9 year old son.'\n",
      "  'Inexpensive tablet for him to use and learn on, step up from the NABI. He was thrilled with it, learn how to Skype on it already...'\n",
      "  5.0]\n",
      " ...\n",
      " ['Love it'\n",
      "  'Simply the best to watch tv series and movies. It works even better if you are an Amazon Prime subscriber, with access to a many free goodies.'\n",
      "  5.0]\n",
      " ['Try it, you will like it'\n",
      "  'I was looking for ways to cut cost from a raising cable bill and a friend suggested I try the Amazon Fire. At first I didn���t know if this was something I could do. Once I was able to maneuver through the process, I love it.'\n",
      "  4.0]\n",
      " ['Great little device'\n",
      "  'I enjoy my kindle tv, it beats paying for cable every month ������'\n",
      "  4.0]]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274fdf3-083a-4e48-8a2e-b0dabc9467ed",
   "metadata": {},
   "source": [
    "Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58179eb6-7d28-423f-b8d7-7bff34ca4541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "# Downloading stopwords which does not have much signifcance\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Stemmer will reduce words in their root form\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "all_stopwords = stopwords.words('english')\n",
    "\n",
    "# Removing some stopwords which have significance effect in building this model\n",
    "rem = ['not', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \n",
    "       \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \n",
    "       \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'don', \"don't\", \n",
    "       'just', 'too', 'very', 'no', 'nor', 'only', 'own', 'same', 'again', 'against', 'but',]\n",
    "for s in rem:\n",
    "    all_stopwords.remove(s)\n",
    "    \n",
    "def find_clean_text(temp):\n",
    "    # Removing all characters other than alphabet\n",
    "    temp = re.sub('[^a-zA-Z]', ' ', temp)\n",
    "    temp = temp.lower()\n",
    "    temp = temp.split()\n",
    "    temp = [ps.stem(word) for word in temp if not word in set(all_stopwords)]\n",
    "    temp = ' '.join(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ae3f840-1222-4252-a71e-1131a67f94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(X.shape[0]):\n",
    "    # Concatenating both title and detailed review\n",
    "    temp = X[i][0] + ' ' + X[i][1]\n",
    "    temp = find_clean_text(temp)\n",
    "    corpus.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795b13a-e80b-4330-a251-f628797409cd",
   "metadata": {},
   "source": [
    "Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed4cdce-de5e-4b9e-b18f-279c407e0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 3000)\n",
    "X  = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "# Adding rating in the matrix of feature X\n",
    "rating = rating.reshape(rating.shape[0],1)\n",
    "X = np.append(X,rating,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8d07d-912d-4617-aec3-4b198d6a8d3d",
   "metadata": {},
   "source": [
    "Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a78fe98-48cc-4ec8-afdd-95ff19c14b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into test set and train set which have equal percentage of data with both positive and negative review\n",
    "#This is done as precautionary measure considering that very small number (approx 1300 out of 34000) data have negative review.\n",
    "pos_x = []\n",
    "pos_y = []\n",
    "neg_x = []\n",
    "neg_y = []\n",
    "for i in range(X.shape[0]):\n",
    "    if y[i]==1:\n",
    "        pos_x.append(X[i])\n",
    "        pos_y.append(y[i])\n",
    "    else:\n",
    "        neg_x.append(X[i])\n",
    "        neg_y.append(y[i])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(pos_x, pos_y, test_size = 0.20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(neg_x, neg_y, test_size = 0.20)\n",
    "\n",
    "for i in range(len(X_train1)):\n",
    "    X_train.append(X_train1[i])\n",
    "    y_train.append(y_train1[i])\n",
    "for i in range(len(X_test1)):\n",
    "    X_test.append(X_test1[i])\n",
    "    y_test.append(y_test1[i])\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e928f1-c6b5-451d-af79-7680437b123e",
   "metadata": {},
   "source": [
    "Training the Multinomial Naive Bayes on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7a04eff-1a97-40be-b66b-d2d9f1b07e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a365b45-d68d-4d6e-a600-1f8dc43f2605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on training set :\n",
      "Confusion matrix :\n",
      "[[  777   330]\n",
      " [  909 25233]]\n",
      "accuracy :  0.9545304414840912\n",
      "Result on test set :\n",
      "Confusion matrix :\n",
      "[[ 177  100]\n",
      " [ 234 6302]]\n",
      "accuracy 0.9509760751504477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print('Result on training set :')\n",
    "print('Confusion matrix :')\n",
    "print(confusion_matrix(y_train,classifier.predict(X_train)))\n",
    "print('accuracy : ',accuracy_score(y_train, classifier.predict(X_train)))\n",
    "\n",
    "print('Result on test set :')\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('Confusion matrix :')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('accuracy',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caee851-f9d0-42dc-bec7-854e96f7b5aa",
   "metadata": {},
   "source": [
    "Making Prediction on some reviews from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c4c5c5a-3562-4399-9504-5bce1a48b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : My 3 yr old grandson loves it! \n",
      "Review : My grandson really enjoys this tablet, ease of use and lots of different educational programs. Must remember to charge tablet everynight. \n",
      "Rating : 5.0\n",
      "True value : True\n",
      "Prediction : [1]\n"
     ]
    }
   ],
   "source": [
    "random.seed(13)\n",
    "index = random.randrange(dataset.shape[0])\n",
    "print('Title :',dataset[0][index],'\\nReview :',dataset[1][index],'\\nRating :',dataset[2][index])\n",
    "print(\"True value :\", dataset[3][index])\n",
    "print(\"Prediction :\",classifier.predict(np.append(cv.transform([find_clean_text(dataset[0][index]+' '+dataset[1][index])]).toarray(),[[dataset[3][index]]],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "903f206c-9abb-41e6-9794-33d0fa8c4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Hate Amazon \n",
      "Review : Hate Amazon! The app store doesn't have cool apps! \n",
      "Rating : 3.0\n",
      "True value : False\n",
      "Prediction : [0]\n"
     ]
    }
   ],
   "source": [
    "index = random.randrange(dataset.shape[0])\n",
    "print('Title :',dataset[0][index],'\\nReview :',dataset[1][index],'\\nRating :',dataset[2][index])\n",
    "print(\"True value :\", dataset[3][index])\n",
    "print(\"Prediction :\",classifier.predict(np.append(cv.transform([find_clean_text(dataset[0][index]+' '+dataset[1][index])]).toarray(),[[dataset[3][index]]],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebc8119a-009e-43a9-8205-4f44b3e8f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Nice product for the price \n",
      "Review : We are used to iPads in our house. This has taken some learning to get used to a slightly different format, but it works great!! The price point is perfect for kids to use without the worry. \n",
      "Rating : 4.0\n",
      "True value : True\n",
      "Prediction : [1]\n"
     ]
    }
   ],
   "source": [
    "index = random.randrange(dataset.shape[0])\n",
    "print('Title :',dataset[0][index],'\\nReview :',dataset[1][index],'\\nRating :',dataset[2][index])\n",
    "print(\"True value :\", dataset[3][index])\n",
    "print(\"Prediction :\",classifier.predict(np.append(cv.transform([find_clean_text(dataset[0][index]+' '+dataset[1][index])]).toarray(),[[dataset[3][index]]],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af179e2b-7659-40c9-a0b0-87d0438c64a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
